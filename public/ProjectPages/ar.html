<html>
    <head>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href = "./css/project-page.css">
    </head>
    <body>
    <div class = "project-content">
        <div class = "project-title">
            <h1 class = "display-3">AR-based Labeling for DNN Fine-tuning</h1>
        </div>
        <div class = "button-container">
            <a href = "../index.html"><button>Back to Home</button></a>
        </div>        
        <h3>Context and Problem</h3>
        <p>
            Augmented reality (AR), a technology that superimposes virtual elements 
            on a real-life view, has recently been integrated into object detection. 
            Despite object detection models' increasing accuracies, 
            humans still need to label images in their training datasets. 
            This is a time-consuming process that involves manually drawing bounding boxes 
            around specific objects in images and associating these boxes with labels. 
            As a part of my senior thesis project in computer science under the supervision of 
            Prof. Maria Gorlatova, I designed a smartphone AR application where a user 
            and a fine-tuned object detection and segmentation model  
            (Faster RCNN) collaboratively generate labels of lemur images 
            to shorten the amount of labeling time. 
        </p>

        <h3>AR-based Object Labeling</h3>
        <p>Below are screenshots from the smartphone AR application I designed.</p>
        <div class = "image-container">
            <img style = "width: 80em;" src = "../images/ar-interface.png">
        </div>
        <p>
            With the Faster RCNN model suggesting possible labels for lemurs detected 
            from the smartphoneâ€™s camera, the user only needs to indicate, 
            using buttons in the application's UI, 
            whether the labels are correct and select the correct labels 
            if the suggested ones are incorrect.<br><br>
            When the user presses the "Start" button as in the far left image, the application suggests a label of the 
            detected lemur, along with a bounding box around the lemur, as in the image in the second image from the left. 
            <br><br>
            If the suggested label is incorrect, the user can choose a different label as in the third image from the left. 
            If the suggested label is correct, the user can move to a screen where they can press the "Capture" button to 
            capture and save images of the detected lemur from different camera view points, along with its bounding box and 
            label information. 
        </p> 

        <h3>Reducing Latency in Label Generation</h3>
        
        <div class = "image-container">
            <img class = "ar-img" src="../images/system_diagram.png"/>
        </div>  
        
        <p>
            It is time-consuming to run computation-heavy programs 
            like inferences with Faster RCNN on a smartphone, which has low computing power compared to most desktop computers. 
            To address this issue, I built a pipeline that splits the label generation task
            between a smartphone and an edge.<br><br> 
            In this pipeline, which is shown above, the smartphone AR application sends captured lemur images to a server 
            running on a desktop computer. 
            Stored in the computer is a program that takes the images as 
            inputs and generates labels of lemurs detected in the images using 
            a fine-tuned Faster RCNN model. The program sends the labels back to the smartphone application 
            so that the application can display the suggested labels for the user to confirm.
        </p>                

        <h3>Conclusion</h3>
        <p>
            It is commonly known that recently developed technologies such as 
            object detection often require costly electronic devices with large storage spaces 
            and computing power. 
            This project started my interest in making such technologies 
            more readily available to users of lower end but more widespread 
            electronic devices like smartphones. Through this project, I also 
            earned the honor of graduating from Duke University with <a href = "./anonymized.html">high distinction in computer science</a>.
        </p> 
        <!-- Original link: https://www.cs.duke.edu/news/articles/4144 -->
        <div class = "button-container">
            <a href = "../index.html"><button>Back to Home</button></a>
        </div>
    </div>
</body>
</html>